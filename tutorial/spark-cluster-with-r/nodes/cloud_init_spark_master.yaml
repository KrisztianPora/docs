#cloud-config

write_files:

############################
# SCRIPT TO CREATE SPARKUSER
############################
- path: /bin/create-user.sh
  content: |
    #!/bin/bash
    echo "Creating SPARKUSER starts."
    adduser --disabled-password --gecos "" sparkuser
    echo "sparkuser:lpds" | chpasswd
    echo "Creating SPARKUSER finished."
  permissions: '755'

###########################
# SCRIPT TO INSTALL RSTUDIO
###########################
- path: /bin/install-studio.sh
  content: |
    #!/bin/bash
    echo "Install RSTUDIO starts."
    #Install R
    sudo apt-get update
    sudo apt-get install r-base -y

    #Install RStudio Server
    sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys E084DAB9
    sudo add-apt-repository 'deb https://ftp.ussg.iu.edu/CRAN/bin/linux/ubuntu xenial/'
    sudo apt-get update
    sudo apt-get install r-base
    sudo apt-get install r-base-dev
    sudo apt-get install gdebi-core
    wget https://download2.rstudio.org/rstudio-server-1.1.463-amd64.deb
    sudo gdebi rstudio-server-1.1.463-amd64.deb -n
    sudo apt-get -y install libpango1.0-dev
    sudo apt-get -y install libcurl4-gnutls-dev
    sudo apt-get -y install libssl-dev
    sudo apt-get -y install libxml2-dev
    echo "Install RSTUDIO finished."
  permissions: '755'


################################
# SCRIPT TO INSTALL HADOOP
################################
- path: /bin/hadoop-install-hadoop.sh
  content: |
    #!/bin/bash
    echo "Install HADOOP starts."
    wget -nc http://xenia.sote.hu/ftp/mirrors/www.apache.org/hadoop/common/hadoop-2.9.2/hadoop-2.9.2.tar.gz -O /home/sparkuser/hadoop-2.9.2.tar.gz
    tar -xvf /home/sparkuser/hadoop-2.9.2.tar.gz --directory /home/sparkuser
    mv /home/sparkuser/hadoop-2.9.2 /home/sparkuser/hadoop
    rm /home/sparkuser/hadoop-2.9.2.tar.gz
    echo "Install HADOOP finished."
  permissions: '755'

################################
# HADOOP CONFIGURATION FILES
################################

- path: /tmp/hadoop/configs/hdfs-site.xml
  content: |
   <configuration>
    <property>
     <name>dfs.namenode.http-address</name>
      <value>HadoopMaster:50070</value>
    </property>
    <property>
      <name>dfs.name.dir</name>
      <value>/tmp</value>
      <final>true</final>
    </property>
    <property>
       <name>dfs.permissions</name>
       <value>false</value>
    </property>
    <property>
      <name>dfs.datanode.du.reserved</name>
      <value>500000000</value>
    </property>
    <property>
      <name>dfs.hosts.exclude</name>
      <value>/etc/hadoop/conf/dfs.exclude</value>
    </property>
   </configuration>
  permissions: '644'

- path: /tmp/hadoop/configs/core-site.xml
  content: |
      <configuration>
      <property>
        <name>fs.default.name</name>
        <value>hdfs://HadoopMaster:9000</value>
      </property>
      </configuration>
  permissions: '644'

- path: /tmp/hadoop/webconfigs/web.xml
  content: |
    <?xml version="1.0" encoding="UTF-8"?>
    <web-app version="2.4" xmlns="http://java.sun.com/xml/ns/j2ee">
      <security-constraint>
          <web-resource-collection>
              <web-resource-name>Protected</web-resource-name>
              <url-pattern>/*</url-pattern>
          </web-resource-collection>
          <auth-constraint>
              <role-name>admin</role-name>
          </auth-constraint>
      </security-constraint>
      <login-config>
          <auth-method>BASIC</auth-method>
          <realm-name>realm</realm-name>
      </login-config>
    </web-app>
  permissions: '644'

- path: /tmp/hadoop/webconfigs/jetty-web.xml
  content: |
    <Configure class="org.mortbay.jetty.webapp.WebAppContext">
     <Get name="securityHandler">
      <Set name="userRealm">
        <New class="org.mortbay.jetty.security.HashUserRealm">
          <Set name="name">realm</Set>
          <Set name="config">/home/sparkuser/hadoop/etc/hadoop/realm.properties</Set>
        </New>
      </Set>
     </Get>
    </Configure>
  permissions: '644'


################################
# SCRIPT TO SETUP HADOOP CONFIG
################################
- path: /bin/hadoop-setup-config.sh
  content: |
    #!/bin/bash
    echo "Configure HADOOP starts."
    mv /tmp/hadoop/configs/* /home/sparkuser/hadoop/etc/hadoop
    mv /tmp/hadoop/webconfigs/* /home/sparkuser/hadoop/share/hadoop/hdfs/webapps/hdfs/WEB-INF/.
    echo "spark: lpds, admin" >> /home/sparkuser/hadoop/etc/hadoop/realm.properties

    #set JAVA HOME in hadoop env
    echo "export JAVA_HOME=/usr/lib/jvm/java-8-oracle/jre" >>/home/sparkuser/hadoop/etc/hadoop/hadoop-env.sh
    echo "export HADOOP_PID_DIR=/home/sparkuser/hadoop-2.9.2" >> /home/sparkuser/hadoop/etc/hadoop/hadoop-env.sh
    echo "export HADOOP_LOG_DIR=/home/sparkuser/hadoop-2.9.2/logs" >> /home/sparkuser/hadoop/etc/hadoop/hadoop-env.sh

    #SET HOSTS FILE
    privateip=`hostname -i`
    hostname=`hostname -s`
    echo "$privateip $hostname" >> /etc/hosts

    masterip=`ifconfig | awk '/inet addr/{print substr($2,6)}' | grep -v 127.0.0.1 | head -n 1`
    sed -i 's/HadoopMaster/'$masterip'/g' /home/sparkuser/hadoop/etc/hadoop/core-site.xml
    sed -i 's/HadoopMaster/'$masterip'/g' /home/sparkuser/hadoop/etc/hadoop/hdfs-site.xml
    chown -R sparkuser:sparkuser /home/sparkuser/hadoop
    echo "Configure HADOOP finished."
  permissions: '755'


################################
# SCRIPT TO LAUNCH HDFS
################################
- path: /bin/launch-hadoop.sh
  content: |
    #!/bin/bash
    echo "Launch HADOOP starts."
    su - sparkuser -c "echo 'Y' | /home/sparkuser/hadoop/bin/hdfs namenode -format hdfs_cluster"
    su - sparkuser -c "/home/sparkuser/hadoop/sbin/hadoop-daemon.sh start namenode"
    #mkdir /home/hdfs
    #chown sparkuser:sparkuser /home/hdfs
    echo "Launch HADOOP finished."
  permissions: '755'


################################
# SCRIPT TO INSTALL JAVA
################################
- path: /bin/spark-install-java.sh
  content: |
    #!/bin/bash
    echo "Install JAVA starts."
    sudo add-apt-repository ppa:webupd8team/java -y
    sudo apt-get update
    echo debconf shared/accepted-oracle-license-v1-1 select true | sudo debconf-set-selections
    echo debconf shared/accepted-oracle-license-v1-1 seen true | sudo debconf-set-selections
    sudo apt-get install oracle-java8-installer -y    
    echo "Install JAVA finished."
  permissions: '755'


################################
# SCRIPT TO INSTALL APACHE SPARK
################################
- path: /bin/spark-install-spark.sh
  content: |
    echo "Install SPARK starts."
    wget http://xenia.sote.hu/ftp/mirrors/www.apache.org/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz -O /home/sparkuser/spark-2.4.1-bin-hadoop2.7.tgz
    tar zxvf /home/sparkuser/spark-2.4.1-bin-hadoop2.7.tgz  --directory /home/sparkuser
    mv /home/sparkuser/spark-2.4.1-bin-hadoop2.7 /home/sparkuser/spark
    rm /home/sparkuser/spark-2.4.1-bin-hadoop2.7.tgz
    echo "Install SPARK finished."
  permissions: '755'

################################
# SCRIPT TO SETUP SPARK CONFIG
################################
- path: /bin/spark-setup-config.sh
  content: |
    #!/bin/bash
    echo "Configure SPARK starts."
    cp /home/sparkuser/spark/conf/spark-env.sh.template /home/sparkuser/spark/conf/spark-env.sh
    masterip=`ifconfig | awk '/inet addr/{print substr($2,6)}' | grep -v 127.0.0.1 | head -n 1`
    echo "SPARK_MASTER_HOST='$masterip'" >> /home/sparkuser/spark/conf/spark-env.sh
    chown -R sparkuser:sparkuser /home/sparkuser/spark
    echo "Configure SPARK ends."
  permissions: '755'

########################################
# SCRIPT TO SETUP SECURITY FOR SPARK GUI
########################################
- path: /bin/spark-gui-sec.sh
  content: |
    #!/bin/bash
    echo "Configure GUI SECURITY starts."
    wget https://gitlab.com/lpds-public/occopus-ml/raw/master/tutorials/ext_dep/spark-gui-sec.tgz?inline=false -O /home/sparkuser/spark-gui-sec.tgz
    tar zxvf /home/sparkuser/spark-gui-sec.tgz --directory /home/sparkuser
    cp /home/sparkuser/spark-gui-sec/basicAuthenticationFilter-0.0.1-SNAPSHOT.jar /home/sparkuser/spark/jars/.
    rm -r /home/sparkuser/spark-gui-sec*
    echo "spark.master.rest.enabled    false" >>/home/sparkuser/spark/conf/spark-defaults.conf
    echo "spark.ui.filters hu.sztaki.lpds.spark.authentication.BasicAuthenticationFilter" >> /home/sparkuser/spark/conf/spark-defaults.conf
    echo "spark.hu.sztaki.lpds.spark.authentication.BasicAuthenticationFilter.params username=spark,password=lpds,realm=realm" >> /home/sparkuser/spark/conf/spark-defaults.conf
    echo "Configure GUI SECURITY ends."
  permissions: '755'
  
runcmd:
#Create USER
- /bin/create-user.sh
#Launch RSTUDIO
- /bin/install-studio.sh
#Install JAVA
- /bin/spark-install-java.sh
#Install HADOOP
- /bin/hadoop-install-hadoop.sh
#Configure HADOOP
- /bin/hadoop-setup-config.sh
#Launch HDFS
- /bin/launch-hadoop.sh
#Install SPARK
- /bin/spark-install-spark.sh
#Setup SPARK
- /bin/spark-setup-config.sh
#Setup GUI SECURITY
- /bin/spark-gui-sec.sh
#Launch SPARK
- su - sparkuser -c /home/sparkuser/spark/sbin/start-master.sh
- echo "SPARK DEPLOYMENT DONE."
